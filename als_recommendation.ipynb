{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%flake8_on --max_line_length 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import timeit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.als_recommender import AlternatingLeastSquares\n",
    "from source import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = utils.create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "als = AlternatingLeastSquares()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 50000...\n",
      "11.00 min\n",
      "{'sample_size': 50, 'runtime': 660.1536158849999, 'rmse_train': 0.7679406645923914, 'rmse_test': 0.9610156344288839, 'top_k_precision_train': 1.0, 'top_k_precision_test': 0.9562162162162166, 'coverage_train': 0.17706517950505402, 'coverage_test': 0.24398745207389333}\n",
      "\n",
      "Running 100000...\n",
      "12.17 min\n",
      "{'sample_size': 100, 'runtime': 729.9904157599999, 'rmse_train': 0.7870209361644016, 'rmse_test': 0.9212674183860323, 'top_k_precision_train': 1.0, 'top_k_precision_test': 0.9566333808844506, 'coverage_train': 0.18650306748466258, 'coverage_test': 0.2591411042944785}\n",
      "\n",
      "Running 150000...\n",
      "13.15 min\n",
      "{'sample_size': 150, 'runtime': 788.9776838819998, 'rmse_train': 0.7894360085317811, 'rmse_test': 0.917336765301196, 'top_k_precision_train': 1.0, 'top_k_precision_test': 0.9611278952668676, 'coverage_train': 0.18190605064759327, 'coverage_test': 0.2522714092402861}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8:1: W293 blank line contains whitespace\n",
      "28:1: W293 blank line contains whitespace\n",
      "56:1: W293 blank line contains whitespace\n",
      "59:1: W293 blank line contains whitespace\n",
      "63:38: W291 trailing whitespace\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i in [50, 100, 150]:\n",
    "    print(f'Running {i*1000}...')\n",
    "\n",
    "    train, test = utils.prepare_data(spark, i*1000)\n",
    "    pd_train, pd_test = train.toPandas(), test.toPandas()\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    als.grid_search(train, rank=[10], max_iter=[5],\n",
    "                    reg_param=np.linspace(0.05, 0.3, 10), num_folds=2,\n",
    "                    metric='rmse', parallelism=2)\n",
    "    stop = timeit.default_timer()\n",
    "    runtime = stop - start\n",
    "    print(f'{runtime/60 :.2f} min')\n",
    "\n",
    "    pred_ratings, pred_rankings = als.predict(test)\n",
    "    test_rmse = als.rmse()\n",
    "    test_precision = als.precision_at_k(k)\n",
    "\n",
    "    pd_pred_ratings = pred_ratings.toPandas()\n",
    "    pd_pred_rankings = pred_rankings.toPandas()\n",
    "\n",
    "    rmse_by_user = utils.rmse_distribution(pd_pred_ratings, 'userId')\n",
    "    rmse_by_movie = utils.rmse_distribution(pd_pred_ratings, 'movieId')\n",
    "\n",
    "    top_k_precision_by_user = utils.top_k_precision_distribution(pd_pred_rankings, k)\n",
    "\n",
    "    pd_pred_rankings['predictedRanking'] = pd_pred_rankings.predictedRanking.apply(lambda x: x[:5])\n",
    "    test_coverage = utils.calculate_coverage(pd.merge(pd_test, pd_pred_rankings, on='userId'))\n",
    "\n",
    "    experiment_title = f'ALS_{i}_Dist_RMSE_User'\n",
    "    with open(f'data/results/{experiment_title}.pkl', 'wb') as f:\n",
    "        pickle.dump([rmse_by_user, experiment_title], f)\n",
    "\n",
    "    experiment_title = f'ALS_{i}_Dist_RMSE_Movie'\n",
    "    with open(f'data/results/{experiment_title}.pkl', 'wb') as f:\n",
    "        pickle.dump([rmse_by_movie, experiment_title], f)\n",
    "\n",
    "    experiment_title = f'ALS_{i}_Dist_Precision_Movie'\n",
    "    with open(f'data/results/{experiment_title}.pkl', 'wb') as f:\n",
    "        pickle.dump([top_k_precision_by_user, experiment_title], f)\n",
    "\n",
    "    experiment_title = f'ALS_{i}_Hyper_RMSE'\n",
    "    reg_params = [r['regParam'] for r in als.results]\n",
    "    rmses = [r['rmse'] for r in als.results]\n",
    "\n",
    "    result = [experiment_title, pd.Series(reg_params), pd.Series(rmses)]\n",
    "    with open(f'data/results/{experiment_title}.pkl', 'wb') as f:\n",
    "        pickle.dump(result, f)\n",
    "\n",
    "    _, pred_rankings = als.predict(train)\n",
    "    train_rmse = als.rmse()\n",
    "    train_precision = als.precision_at_k(k)\n",
    "    pd_pred_rankings = pred_rankings.toPandas()\n",
    "\n",
    "    pd_pred_rankings['predictedRanking'] = pd_pred_rankings.predictedRanking.apply(lambda x: x[:5])\n",
    "    train_coverage = utils.calculate_coverage(pd.merge(pd_train, pd_pred_rankings, on='userId'))\n",
    "\n",
    "    result = {'sample_size': i,\n",
    "              'runtime': runtime,\n",
    "              'rmse_train': train_rmse,\n",
    "              'rmse_test': test_rmse,\n",
    "              'top_k_precision_train': train_precision,\n",
    "              'top_k_precision_test': test_precision,\n",
    "              'coverage_train': train_coverage,\n",
    "              'coverage_test': test_coverage}\n",
    "    results.append(result)\n",
    "    print(result)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_pickle('data/results/ALS_result.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
